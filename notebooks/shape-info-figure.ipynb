{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import functools\n",
    "import operator \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "\n",
    "from kedro.extras.datasets.pickle import PickleDataSet\n",
    "from kedro.config import ConfigLoader\n",
    "\n",
    "import kornia.augmentation as K\n",
    "\n",
    "import monai\n",
    "from monai.networks import one_hot\n",
    "from scipy import ndimage\n",
    "\n",
    "from skimage.draw import disk\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "sys.path.append(os.path.abspath('../src/'))\n",
    "\n",
    "from src.tagseg.metrics.shape import ShapeLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def losses(input, target, smooth_k):\n",
    "    input = torch.Tensor(input).float().unsqueeze(0)\n",
    "    target = torch.Tensor(target).long().unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    sl = ShapeLoss(to_onehot_y=True, include_background=False, smooth_k=smooth_k)(input, target)\n",
    "    cel = torch.nn.CrossEntropyLoss()(input, target[0])\n",
    "    hd = monai.metrics.compute_hausdorff_distance(input[0, 1].unsqueeze(0).unsqueeze(0), target)\n",
    "\n",
    "    return sl.item(), cel.item(), hd.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_maps(target, smooth_k=1e-2):\n",
    "\n",
    "        target = torch.Tensor(target).long().unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        target = one_hot(target, 2)\n",
    "        target = target[:, 1:]\n",
    "\n",
    "        distance_maps = torch.Tensor()\n",
    "\n",
    "        for _im in range(target.shape[0]):\n",
    "            distance_map = torch.Tensor()\n",
    "\n",
    "            for _class in range(target.shape[1]):\n",
    "                roi = target[_im, _class].numpy()\n",
    "\n",
    "                dt = ndimage.distance_transform_edt(roi)\n",
    "                dt /= dt.max() + 1e-8\n",
    "                dt_n = ndimage.distance_transform_edt(1 - roi)\n",
    "                dt_n /= dt_n.max() + 1e-8\n",
    "\n",
    "                shape_information = (1 - dt) #  * roi + (dt_n - 1) * (1 - roi)\n",
    "                sdm = torch.Tensor(1 / (1 + np.exp(-shape_information / smooth_k))) * roi\n",
    "                distance_map = torch.cat([distance_map, sdm.unsqueeze(0)], axis=0)\n",
    "\n",
    "            distance_maps = torch.cat([distance_maps, distance_map.unsqueeze(0)], axis=0)\n",
    "\n",
    "        distance_maps = distance_maps.to(target.device)\n",
    "\n",
    "        return distance_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = []\n",
    "\n",
    "input = np.zeros((256, 256))\n",
    "input[disk((128, 128), 64)] = 1\n",
    "input[disk((128, 128), 32)] = 0\n",
    "input = np.array([1 - input, input])\n",
    "\n",
    "target = np.zeros((256, 256))\n",
    "target[disk((128, 128), 64)] = 1\n",
    "target[disk((128, 128), 32)] = 0\n",
    "\n",
    "cases.append(dict(input=input, target=target))\n",
    "\n",
    "input = np.zeros((256, 256))\n",
    "input[disk((128, 128), 86)] = 1\n",
    "input[disk((128, 128), 16)] = 0\n",
    "input = np.array([1 - input, input])\n",
    "\n",
    "target = np.zeros((256, 256))\n",
    "target[disk((128, 128), 64)] = 1\n",
    "target[disk((128, 128), 32)] = 0\n",
    "\n",
    "cases.append(dict(input=input, target=target))\n",
    "\n",
    "input = np.zeros((256, 256))\n",
    "input[disk((128, 128), 64)] = 1\n",
    "input[disk((128, 128), 32)] = 0\n",
    "input = np.array([1 - input, input])\n",
    "\n",
    "target = np.zeros((256, 256))\n",
    "target[disk((128, 128), 86)] = 1\n",
    "target[disk((128, 128), 16)] = 0\n",
    "\n",
    "cases.append(dict(input=input, target=target))\n",
    "\n",
    "input = np.zeros((256, 256))\n",
    "input[disk((180, 180), 64)] = 1\n",
    "input[disk((180, 180), 32)] = 0\n",
    "input = np.array([1 - input, input])\n",
    "\n",
    "target = np.zeros((256, 256))\n",
    "target[disk((90, 90), 64)] = 1\n",
    "target[disk((90, 90), 32)] = 0\n",
    "\n",
    "cases.append(dict(input=input, target=target))\n",
    "\n",
    "input = np.zeros((256, 256))\n",
    "input[disk((132, 128), 64)] = 1\n",
    "input[disk((132, 128), 32)] = 0\n",
    "input = np.array([1 - input, input])\n",
    "\n",
    "target = np.zeros((256, 256))\n",
    "target[disk((112, 128), 64)] = 1\n",
    "target[disk((112, 128), 32)] = 0\n",
    "\n",
    "cases.append(dict(input=input, target=target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['ytick.right'] = plt.rcParams['ytick.labelright'] = True\n",
    "plt.rcParams['ytick.left'] = plt.rcParams['ytick.labelleft'] = False\n",
    "\n",
    "fig, ax = plt.subplots(4, len(cases), figsize=(6, 6))\n",
    "\n",
    "for i, case in enumerate(cases):\n",
    "\n",
    "    ax[0, i].imshow(case['input'][1], cmap='Blues', alpha=0.5)\n",
    "    ax[0, i].imshow(case['target'], cmap='Reds', alpha=0.5)\n",
    "    ax[0, i].axis('off')\n",
    "\n",
    "\n",
    "    dm = distance_maps(case['target'], smooth_k=.2)\n",
    "    im = ax[1, i].imshow(dm[0, 0], cmap='cividis', vmin=0., vmax=1.)\n",
    "    ax[1, i].axis('off')\n",
    "\n",
    "    if i == len(cases) - 1:\n",
    "        divider = make_axes_locatable(ax[1, i])\n",
    "        cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "        plt.colorbar(im, cax=cax)\n",
    "\n",
    "    diff = (torch.Tensor(case['input']).unsqueeze(0)[:, 1:] - dm).abs()\n",
    "    im = ax[2, i].imshow(diff[0, 0], cmap='cividis', vmin=0., vmax=1.)\n",
    "    ax[2, i].axis('off')\n",
    "\n",
    "    if i == len(cases) - 1:\n",
    "        divider = make_axes_locatable(ax[2, i])\n",
    "        cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "        plt.colorbar(im, cax=cax)\n",
    "\n",
    "    loss_names = ['SL', 'CEL', 'HD']\n",
    "    loss_values = list(losses(case['input'], case['target'], smooth_k=.2))\n",
    "    ax[3, i].bar(loss_names[:2], loss_values[:2], color=['#219EBC', '#FFB703'])\n",
    "    ax[3, i].set_ylim(0, 2.0)\n",
    "    if i < len(cases) - 1:\n",
    "        ax[3, i].set_yticks([])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('../figures/shape-loss.svg', dpi=150, format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0ad42e69c0d21e96d3d26e0b34570ca4969313104102badd5550b873ed7930ce"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('tagroi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
