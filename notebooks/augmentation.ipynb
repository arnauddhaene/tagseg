{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import useful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import kornia as kn\n",
    "import kornia.augmentation as K\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "\n",
    "from kedro.extras.datasets.pickle import PickleDataSet\n",
    "from kedro.config import ConfigLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from src.tagseg.models.unet import UNet\n",
    "from src.tagseg.metrics.metrics import dice_loss, evaluate\n",
    "from src.tagseg.data.acdc_dataset import SimulateTags\n",
    "from src.tagseg.data.acdc_dataset import AcdcDataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up connection to dataset\n",
    "\n",
    "Raw images and labels (of varying sizes) are saved in `ims` and `las` respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_paths = [\"../conf/base\", \"../conf/local\"]\n",
    "conf_loader = ConfigLoader(conf_paths)\n",
    "conf_catalog = conf_loader.get(\"catalog*\", \"catalog*/**\")\n",
    "\n",
    "dataset = PickleDataSet(filepath='../' + conf_catalog['acdc_data_tagged']['filepath']).load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch all images and their labels without any preprocessing or augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose: bool = True\n",
    "\n",
    "# Get all patient folders from main raw downloaded ACDC directory\n",
    "patient_paths = [ppath for ppath in Path(acdc_path).iterdir() if ppath.is_dir()]\n",
    "\n",
    "ims: List[np.ndarray] = []\n",
    "las: List[np.ndarray] = []\n",
    "\n",
    "accepted_classes: set = set([0., 1., 2., 3.])\n",
    "\n",
    "# Iterate over all patients\n",
    "patients_pbar = tqdm(patient_paths, leave=True)\n",
    "for ppath in patients_pbar:\n",
    "    if verbose > 0:\n",
    "        patients_pbar.set_description(f'Processing {ppath.name}...')\n",
    "    \n",
    "    # Loading .nii.gz files in handled in the `Patient` class\n",
    "    patient = Patient(ppath)\n",
    "    assert len(patient.images) == len(patient.masks)\n",
    "    \n",
    "    # Loop through each patient's list of images (around 10 per patient)\n",
    "    for image, label in zip(patient.images, patient.masks):        \n",
    "        image, label = image.astype(np.float64), label.astype(np.float64)\n",
    "\n",
    "        ims.append(image)\n",
    "        las.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test out and visualize different augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_preprocess_image = transforms.Compose([\n",
    "    SimulateTags(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=0.456, std=0.224),\n",
    "    transforms.Resize((256, 256))\n",
    "])\n",
    "\n",
    "_preprocess_label = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((256, 256), interpolation=transforms.InterpolationMode.NEAREST)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = slice(0, 10)\n",
    "\n",
    "images: torch.Tensor = torch.Tensor()\n",
    "labels: torch.Tensor = torch.Tensor()\n",
    "\n",
    "for im, la in tqdm(zip(ims[selection], las[selection]), total=len(ims[selection])):\n",
    "\n",
    "    image = im\n",
    "    image /= image.max()\n",
    "    image = _preprocess_image(image).unsqueeze(0)\n",
    "    image += image.min()\n",
    "    label = _preprocess_label(la)\n",
    "\n",
    "    images = torch.cat((images, image), axis=0)\n",
    "    labels = torch.cat((labels, label), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba: float = 0.2\n",
    "\n",
    "train_aug = K.AugmentationSequential(\n",
    "    K.RandomHorizontalFlip(p=proba),\n",
    "    K.RandomVerticalFlip(p=proba),\n",
    "    K.RandomElasticTransform(p=proba),\n",
    "    K.RandomGaussianNoise(p=proba),\n",
    "    K.RandomSharpness(p=proba),\n",
    "    K.RandomGaussianBlur(kernel_size=(3, 3), sigma=(0.1, 0.1), p=proba),\n",
    "    data_keys=[\"input\", \"mask\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_ims, aug_las = augment(images, labels.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_las.squeeze(1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(10, 6, figsize=(20, 40))\n",
    "\n",
    "for i in range(10):\n",
    "    axes[i, 0].imshow(ims[i], cmap='gray'),         axes[i, 0].axis('off')\n",
    "    axes[i, 1].imshow(las[i]),                      axes[i, 1].axis('off')\n",
    "    axes[i, 2].imshow(images[i, 0], cmap='gray'),   axes[i, 2].axis('off')\n",
    "    axes[i, 3].imshow(labels[i]),                   axes[i, 3].axis('off')\n",
    "    axes[i, 4].imshow(aug_ims[i, 0], cmap='gray'),  axes[i, 4].axis('off')\n",
    "    axes[i, 5].imshow(aug_las[i, 0]),               axes[i, 5].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0ad42e69c0d21e96d3d26e0b34570ca4969313104102badd5550b873ed7930ce"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('tagroi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
