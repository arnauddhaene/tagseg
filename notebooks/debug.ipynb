{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import aim\n",
    "import PIL\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, random_split, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from src.models.unet import UNet\n",
    "from src.training.train import train\n",
    "from src.data.datasets import ACDCDataset\n",
    "from src.training.metrics import dice_score, DiceLoss, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ACDCDataset(path='../../training/', tagged=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set = random_split(dataset, [704, 248], generator=torch.Generator().manual_seed(42))\n",
    "loader_train = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "loader_val = DataLoader(val_set, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = UNet(n_channels=1, n_classes=4, bilinear=True).double()\n",
    "# Load old saved version of the model\n",
    "saved_model = torch.load('../checkpoints/model/model_cine_tag_v1_sd.pt')\n",
    "# Extract UNet if saved model is parallelized\n",
    "# if isinstance(saved_model, nn.DataParallel):\n",
    "    # saved_model = saved_model.module\n",
    "model.load_state_dict(saved_model)\n",
    "\n",
    "# if device.type == 'cuda':\n",
    "    # model = nn.DataParallel(model)\n",
    "    # model.n_classes = model.module.n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets = next(iter(loader_val))\n",
    "images, targets = images.double().to(device), targets.long().to(device)\n",
    "# predict the mask\n",
    "outputs = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(targets.detach().cpu().numpy()[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIL.Image.fromarray(targets.detach().cpu().numpy()[5].astype('uint8') * round(256 / 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aim.Image(targets.detach().cpu().numpy()[5].astype('uint8') * round(256 / 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.detach().cpu().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, loader_train, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets = next(iter(loader_train))\n",
    "images, targets = images.double().to(device), targets.long().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "outputs = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = F.softmax(outputs, dim=1).argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without model.eval()\n",
    "dice_score(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with model.eval()\n",
    "dice_score(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no grad\n",
    "dice_score(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(16, 3, figsize=(10, 40))\n",
    "\n",
    "for i in range(images.shape[0]):\n",
    "\n",
    "    ax[i, 0].imshow(images[i, 0].detach().cpu().numpy()), ax[i, 0].axis('off')\n",
    "    ax[i, 1].imshow(targets[i].detach().cpu().numpy()), ax[i, 1].axis('off')\n",
    "    ax[i, 2].imshow(prediction[i].detach().cpu().numpy()), ax[i, 2].axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, loader_train, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "dice_criterion = DiceLoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=weight_decay, momentum=momentum)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)\n",
    "grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(4):\n",
    "    \n",
    "    dice = torch.zeros(4)\n",
    "    acc_loss = 0.\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    batch_pbar = tqdm(loader_train, total=len(loader_train), unit='batch', leave=False)\n",
    "    for inputs, targets in loader_train:\n",
    "\n",
    "        batch_pbar.set_description(f'Acummulated loss: {acc_loss:.4f}')\n",
    "        # move to device\n",
    "        # target is index of classes\n",
    "        inputs, targets = inputs.double().to(device), targets.long().to(device)\n",
    "        \n",
    "        with torch.cuda.amp.autocast(enabled=amp):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets) + \\\n",
    "                dice_criterion(outputs, targets, exclude_bg=True)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            grad_scaler.scale(loss).backward()\n",
    "            grad_scaler.step(optimizer)\n",
    "            grad_scaler.update()\n",
    "\n",
    "        dice += dice_score(outputs, targets)\n",
    "        acc_loss += loss.item()\n",
    "\n",
    "    # Tracking training performance\n",
    "    train_perf = dice / len(loader_train)\n",
    "    avg_dice = train_perf.mean()\n",
    "\n",
    "    status = f'Epoch {epoch:03} \\t Loss {acc_loss:.4f} \\t Dice {avg_dice:.4f}'\n",
    "    \n",
    "    # Tracking validation performance\n",
    "    val_perf = evaluate(model, loader_val, device)\n",
    "    avg_val_dice = val_perf.mean()\n",
    "    scheduler.step(avg_val_dice)\n",
    "\n",
    "    status += f'\\t Val. Dice {avg_val_dice:.4f}'\n",
    "\n",
    "    print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, mask = next(iter(loader_train))\n",
    "output = model(image.double().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.CrossEntropyLoss()(output, mask.long().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DiceLoss(exclude_bg=True)(output, mask.long().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_score(output, mask.long().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_soft = F.softmax(output, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kornia.utils.one_hot import one_hot\n",
    "\n",
    "target_one_hot = one_hot(mask.long().to(device), 4, device, output.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = (2, 3)\n",
    "intersection = torch.sum(input_soft * target_one_hot, dims)\n",
    "cardinality = torch.sum(input_soft + target_one_hot, dims)\n",
    "\n",
    "dice_score = 2.0 * intersection / (cardinality + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_class = dice_score.mean(dim=0)\n",
    "per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(-per_class[1:] + 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0ad42e69c0d21e96d3d26e0b34570ca4969313104102badd5550b873ed7930ce"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('tagroi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
