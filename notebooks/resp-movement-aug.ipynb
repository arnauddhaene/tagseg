{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from itertools import combinations \n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import scipy as scp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import aim\n",
    "\n",
    "from skimage.draw import disk\n",
    "from skimage.transform import AffineTransform, warp\n",
    "\n",
    "from medpy.metric.binary import dc\n",
    "\n",
    "from monai.metrics import DiceMetric, HausdorffDistanceMetric, compute_meandice\n",
    "from monai.transforms import AsDiscrete, EnsureType, Compose\n",
    "from monai.data import decollate_batch\n",
    "from monai.losses import DiceLoss\n",
    "from monai.networks import one_hot\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "import kornia.augmentation as K\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from kedro.extras.datasets.pickle import PickleDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "from tagseg.models.segmenter import Net\n",
    "from tagseg.models.trainer import Trainer\n",
    "from tagseg.data.utils import load_nii\n",
    "from tagseg.metrics.shape import ShapeDistLoss\n",
    "from tagseg.pipelines.data_splitting.nodes import split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fetch data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract cherry-picked example to test augmentation strategy on and squeeze to remove channel dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_image = '../data/01_raw/acdc-training/patient080/patient080_frame10.nii.gz'\n",
    "path_label = '../data/01_raw/acdc-training/patient080/patient080_frame10_gt.nii.gz'\n",
    "\n",
    "images, label = tuple(map(lambda p: load_nii(p)[0].swapaxes(0, 2), (path_image, path_label)))\n",
    "\n",
    "print(f'Image of shape: {images.shape}, Label of shape: {label.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make the image between 0 and 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = images[2].astype(np.uint8)\n",
    "la = label[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im, cmap='gray')\n",
    "plt.imshow(np.ma.masked_where(la == 0, la), cmap='viridis', alpha=0.5)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tform = AffineTransform(scale=.97, translation=(20, 0))\n",
    "warped = warp(im, tform)\n",
    "\n",
    "plt.imshow(warped, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Works for normal breathing, might not generalize to **intense** breathing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 4000\n",
    "timepoints = np.arange(duration)\n",
    "\n",
    "# Compute x and y coordinates\n",
    "now = (timepoints / (duration * 1.25)) % duration\n",
    "spike = np.exp(np.sin(now * 2 * np.pi)) + 0.5 * np.exp(now)\n",
    "\n",
    "# Normalize to [0, 1]\n",
    "spike = (spike - spike.min()) / (spike.max() - spike.min())\n",
    "\n",
    "plt.plot(timepoints, spike)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's transform the image to get the k-space representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kspace = scp.fft.fftshift(\n",
    "    scp.fft.fft2(la)\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "ax[0].imshow(kspace.real, cmap='gray', clim=(.001 * kspace.real.max())), ax[0].axis('off')\n",
    "ax[1].imshow(kspace.imag, cmap='gray', clim=(.001 * kspace.imag.max())),  ax[1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the motion augmentation\n",
    "\n",
    "_Simple version_\n",
    "* Replace `x` rows with 0 randomly\n",
    "\n",
    "_Moderate version_\n",
    "* Create scaled and translated image\n",
    "* Replace `x` random rows with the created image\n",
    "\n",
    "_Complex version_\n",
    "* Use a respiratory model that transforms image based on time of k-space row acquisition\n",
    "* Create scaled and translated image for each row that will be replaced\n",
    "* Replace rows with the created image for that specific row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformation_params(times: np.ndarray, breathing_duration: int = None) -> List[Dict[str, Any]]:\n",
    "\n",
    "    if breathing_duration is None:\n",
    "        breathing_duration = np.random.normal(4000, 750, size=1)\n",
    "\n",
    "    now = (times / (breathing_duration * 1.25)) % breathing_duration\n",
    "    f = np.exp(np.sin(now * 2 * np.pi)) + 5e-1 * np.exp(now)\n",
    "    intensity = (f - f.min()) / (f.max() - f.min())\n",
    "    \n",
    "    s = 1 - (.5 * intensity)\n",
    "\n",
    "    tx = np.zeros(times.shape[0])\n",
    "    ty = - intensity * 150.\n",
    "    \n",
    "    d_of_l = dict(scale=s, translation=list(zip(*(tx, ty))))\n",
    "\n",
    "    return [dict(zip(d_of_l, t)) for t in zip(*d_of_l.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row_time(\n",
    "    rows: np.ndarray,\n",
    "    segment_duration: int = 8,  # TR\n",
    "    lines_per_segment: int = 4,\n",
    "    heartbeat_duration: int = 1000,\n",
    "    time_frame: int = 0\n",
    ") -> np.ndarray:\n",
    "\n",
    "    if heartbeat_duration is None:\n",
    "        heartbeat_duration = np.random.normal(1200, 250, size=1)\n",
    "\n",
    "    times = (rows % lines_per_segment) * segment_duration + (rows // lines_per_segment) * heartbeat_duration \n",
    "    times += time_frame * lines_per_segment * segment_duration\n",
    "    \n",
    "    return (times).astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TR should probably me around 5 ms\n",
    "- Only 55 - 60 of lines are actually sampled (with grappa)\n",
    "    - Not sure this matters if we get the reconstructed image anyways (jump should be every segment)\n",
    "- Grappa2 goes twice as fast (skips every other lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = np.arange(256)\n",
    "times = get_row_time(rows)\n",
    "\n",
    "plt.plot(rows, times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_kspace(image: np.ndarray):\n",
    "    return scp.fft.fftshift(scp.fft.fft2(scp.fft.fftshift(image)))\n",
    "\n",
    "def to_image(kspace: np.ndarray):\n",
    "    return scp.fft.ifftshift(scp.fft.ifft2(scp.fft.ifftshift(kspace)))\n",
    "\n",
    "def augment(image: np.array, method: str = 'moderate', replacement: str = 'periodic', amount: int = None):\n",
    "    \"\"\"Add motion artifacts to a 2D MRI image\n",
    "\n",
    "    Args:\n",
    "        image (np.array): 2D input image\n",
    "        method (str, optional): Augmentation method, 'simple', 'moderate', or 'complex'. Defaults to 'moderate'.\n",
    "        replacement (str, optional): Row replacement strategy, 'random' or 'periodic'. Defaults to 'period'.\n",
    "        amonut (int, optional): Amount of rows replaced. Defaults to 10% of rows.\n",
    "    \"\"\"\n",
    "\n",
    "    m, n = image.shape[-2:]\n",
    "\n",
    "    kspace = to_kspace(image)\n",
    "    \n",
    "    modded_kspace = kspace.copy()\n",
    "\n",
    "    if amount is None:\n",
    "        amount = m // 10\n",
    "\n",
    "    if replacement == 'periodic':\n",
    "        replacement_rows = np.linspace(0, n, amount, endpoint=False, dtype=np.int32)\n",
    "        \n",
    "    elif replacement == 'random':\n",
    "        replacement_rows = np.random.randint(0, n, amount)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f'replacement should be either periodic or random. Got {replacement}.')\n",
    "\n",
    "    if method == 'simple':\n",
    "        modded_kspace[:, replacement_rows] = np.zeros((m, 1))\n",
    "        \n",
    "    elif method == 'moderate':\n",
    "        # Create transform\n",
    "        tform = AffineTransform(scale=1.1, translation=(10, 10))\n",
    "        # Create fake image the simulates breathing\n",
    "        warped_image = warp(image, tform)\n",
    "        # Transform into kspace\n",
    "        breathing_kspace = to_kspace(warped_image)\n",
    "        \n",
    "        modded_kspace[:, replacement_rows] = breathing_kspace[:, replacement_rows]\n",
    "\n",
    "    elif method == 'complex':        \n",
    "        # get times according to row index\n",
    "        times = get_row_time(replacement_rows)\n",
    "        # get transformation parameters according to time in ms\n",
    "        # this uses our respiratory model\n",
    "        row_trans_params = transformation_params(times)\n",
    "        # create transformed image for each row\n",
    "        # by creating an AffineTransform instance and calling warp foreach\n",
    "        \n",
    "        # tforms = list(map(lambda ps: AffineTransform(**ps), row_trans_params))\n",
    "        # fake_ims = list(map(lambda tf: warp(image, tf), tforms))\n",
    "        # breathing_kspaces = list(map(\n",
    "        #     lambda fim: to_kspace(fim), \n",
    "        #     fake_ims\n",
    "        # ))\n",
    "        # for row, bksp in zip(replacement_rows, breathing_kspaces):\n",
    "        #     modded_kspace[:, row] = bksp[:, row]\n",
    "\n",
    "        for row, ps in zip(replacement_rows, row_trans_params):\n",
    "\n",
    "            # TODO: perform affine transformation in k-space\n",
    "            tform = AffineTransform(**ps)\n",
    "            fake_image = warp(image, tform)\n",
    "            altered_kspace = to_kspace(fake_image)\n",
    "            modded_kspace[:, row] = altered_kspace[:, row]\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f'method should be simple or moderate. Got {method}.')\n",
    "\n",
    "    return np.abs(to_image(modded_kspace))  # , tforms, fake_ims, replacement_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the augmented image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(a):\n",
    "    return (a - a.min()) / (a.max() - a.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f augment augment(im, method='complex', replacement='periodic', amount=216)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = augment(im, method='complex', replacement='periodic', amount=216)\n",
    "# aug, tforms, fims, replacement_rows = augment(im, method='complex', replacement='periodic', amount=216)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20, 10))\n",
    "\n",
    "ax[0].imshow(im, cmap='gray'), ax[0].axis('off'), ax[0].set_title('Original image')\n",
    "ax[1].imshow(aug, cmap='gray'), ax[1].axis('off'), ax[1].set_title('Augmented image')\n",
    "ax[2].imshow((normalize(im) - normalize(aug)) ** 2, cmap='viridis'),  ax[2].axis('off'), ax[2].set_title('Squared Difference')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Additional evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(tforms)\n",
    "\n",
    "diffs = np.empty((n, n), dtype=np.float64)\n",
    "\n",
    "for i, j in combinations(range(len(tforms)), 2):\n",
    "    diffs[i, j] = ((tforms[i].params - tforms[j].params) ** 2).mean()\n",
    "\n",
    "plt.imshow(diffs)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "class VideoAnimation:\n",
    "\n",
    "    def __init__(self, imt: np.ndarray):\n",
    "\n",
    "        self.imt = imt\n",
    "\n",
    "        self.fig, self.axarr = plt.subplots(1, 1, squeeze=False, figsize=(8, 8))\n",
    "        self.fig.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=None, hspace=None)\n",
    "        self.im = self.axarr[0, 0].imshow(self.imt[0], cmap=\"gray\")\n",
    "        self.axarr[0, 0].axis('off')\n",
    "\n",
    "        self.anim = animation.FuncAnimation(\n",
    "            self.fig,\n",
    "            self.animate,\n",
    "            init_func=self.init_animation,\n",
    "            frames=imt.shape[0],\n",
    "            interval=50,\n",
    "            blit=True\n",
    "        )\n",
    "\n",
    "        plt.close()\n",
    "\n",
    "    def init_animation(self):\n",
    "        self.im.set_data(self.imt[0])\n",
    "        return [self.im,]\n",
    "\n",
    "    def animate(self, i):\n",
    "        self.im.set_data(self.imt[i])\n",
    "        return [self.im,] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "va = VideoAnimation(np.array(fims))\n",
    "HTML(va.anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(fims)\n",
    "\n",
    "m, n = np.ceil(total / 6).astype(int), 6\n",
    "\n",
    "fig, ax = plt.subplots(m, n, figsize=(15, m * 4))\n",
    "\n",
    "for i in range(total):\n",
    "\n",
    "    ax[i // n, i % n].imshow(fims[i])\n",
    "    ax[i // n, i % n].axis('off')\n",
    "    ax[i // n, i % n].set_title(f'{i:02}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f96aa06bcc802279cb41a4fef15367898ee8a6505f496b2b6e706331145b8c4d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tagseg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
